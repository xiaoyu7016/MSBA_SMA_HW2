{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WRITING A TWEET COLLECTOR IN PYTHON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from twython import Twython\n",
    "import csv\n",
    "import os\n",
    "from pandas import DataFrame, Series\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Authorization\n",
    "APP_KEY = \"2lzEpNDwz9ieHhr738sXX8Avl\"\n",
    "APP_SECRET = \"z3srlvggHvhCqIBSMnKRbn5OY36B2Z58299ipfKtuRXMqwI4rj\"\n",
    "\n",
    "twitter_get_token = Twython(APP_KEY,APP_SECRET,oauth_version=2)\n",
    "ACCESS_TOKEN = twitter_get_token.obtain_access_token()\n",
    "\n",
    "twitter = Twython(APP_KEY,access_token = ACCESS_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crawl_tweets(topic_string,num_of_calls):\n",
    "    \"\"\"A function to crawl tweets\n",
    "       (1) query topic is specified by \"topic_string\"\n",
    "       (2) num_of_calls has an upper limit of 450 per access token which is valid for 15 min;\n",
    "           each call will crawl 100 tweets\n",
    "       (3) returns a list, each element contains 100 tweets\"\"\"\n",
    "    empty_list = []\n",
    "    for i in range(num_of_calls):\n",
    "        empty_list.append(twitter.search(q=topic_string,lang = 'en',count=100))\n",
    "    return empty_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_tweet_per_element(raw_tweets_list):\n",
    "    empty_list = []\n",
    "    for i in range(len(raw_tweets_list)):\n",
    "        empty_list += raw_tweets_list[i]['statuses']\n",
    "    return empty_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_tweets = crawl_tweets(\"zika\",100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "messaged_tweets = one_tweet_per_element(raw_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(messaged_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# formatting to nice csv-ish file\n",
    "def collect_tweet_level_field_from_each_user(title_string,messaged_tweets_list):\n",
    "    \"\"\"Retrieve info at per-tweet level\"\"\"\n",
    "    empty_list = []\n",
    "    for i in range(len(messaged_tweets_list)):\n",
    "        empty_list.append(messaged_tweets_list[i][title_string])\n",
    "    return empty_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def collect_user_level_field_from_each_user(title_string,messaged_tweets_list):\n",
    "    \"\"\"Retrieve info at per-user level\"\"\"    \n",
    "    empty_list = []\n",
    "    for i in range(len(messaged_tweets_list)):\n",
    "        empty_list.append(messaged_tweets_list[i]['user'][title_string])\n",
    "    return empty_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['entities', 'in_reply_to_user_id_str', 'source', 'place', 'retweeted', 'in_reply_to_status_id_str', 'in_reply_to_user_id', 'truncated', 'id', 'user', 'favorite_count', 'coordinates', 'favorited', 'created_at', 'text', 'possibly_sensitive', 'in_reply_to_screen_name', 'in_reply_to_status_id', 'lang', 'geo', 'is_quote_status', 'retweet_count', 'id_str', 'contributors', 'metadata'])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tweet level fields\n",
    "messaged_tweets[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweet_id = collect_tweet_level_field_from_each_user('id',messaged_tweets)\n",
    "text = collect_tweet_level_field_from_each_user('text',messaged_tweets)\n",
    "retweet_count = collect_tweet_level_field_from_each_user('retweet_count',messaged_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['profile_banner_url', 'follow_request_sent', 'profile_sidebar_border_color', 'followers_count', 'entities', 'has_extended_profile', 'profile_background_image_url', 'description', 'profile_image_url', 'statuses_count', 'screen_name', 'is_translation_enabled', 'time_zone', 'is_translator', 'following', 'favourites_count', 'id', 'default_profile_image', 'profile_background_image_url_https', 'verified', 'profile_sidebar_fill_color', 'profile_text_color', 'utc_offset', 'profile_use_background_image', 'created_at', 'location', 'name', 'profile_link_color', 'profile_image_url_https', 'contributors_enabled', 'lang', 'friends_count', 'protected', 'geo_enabled', 'profile_background_color', 'default_profile', 'listed_count', 'id_str', 'url', 'profile_background_tile', 'notifications'])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# User level fields\n",
    "messaged_tweets[0]['user'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_id = collect_user_level_field_from_each_user('id',messaged_tweets)\n",
    "screen_name = collect_user_level_field_from_each_user('screen_name',messaged_tweets)\n",
    "following = collect_user_level_field_from_each_user('friends_count',messaged_tweets)\n",
    "followers_count = collect_user_level_field_from_each_user('followers_count',messaged_tweets)\n",
    "listed_count = collect_user_level_field_from_each_user('listed_count', messaged_tweets)\n",
    "friends_count = collect_user_level_field_from_each_user('friends_count',messaged_tweets)\n",
    "favourites_count =   collect_user_level_field_from_each_user('favourites_count',messaged_tweets)\n",
    "statuses_count = collect_user_level_field_from_each_user('statuses_count', messaged_tweets)\n",
    "location = collect_user_level_field_from_each_user('location',messaged_tweets)\n",
    "created_at = collect_user_level_field_from_each_user('created_at',messaged_tweets)\n",
    "verified = collect_user_level_field_from_each_user('verified',messaged_tweets)\n",
    "description = collect_user_level_field_from_each_user('description',messaged_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets_dict = {\n",
    "    'tweet_id' : tweet_id,\n",
    "    'text' : text,\n",
    "    'retweet_count' : retweet_count,\n",
    "    'user_id' : user_id,\n",
    "    'screen_name' : screen_name,\n",
    "    'following' : following,\n",
    "    'followers_count' : followers_count,\n",
    "    'listed_count' : listed_count,\n",
    "    'friends_count' : friends_count,\n",
    "    'favourites_count' : favourites_count,\n",
    "    'statuses_count' : statuses_count,\n",
    "    'location' : location,\n",
    "    'created_at' : created_at,\n",
    "    'verified' : verified,\n",
    "    'description' :description\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>followers_count</th>\n",
       "      <th>text</th>\n",
       "      <th>location</th>\n",
       "      <th>description</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>following</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>created_at</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>user_id</th>\n",
       "      <th>verified</th>\n",
       "      <th>tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1596</td>\n",
       "      <td>A doctor connected to Putnam Hospital Center s...</td>\n",
       "      <td>New City, NY</td>\n",
       "      <td>New City Patch is your source for local news.</td>\n",
       "      <td>12248</td>\n",
       "      <td>NewCityPatch</td>\n",
       "      <td>51</td>\n",
       "      <td>7</td>\n",
       "      <td>51</td>\n",
       "      <td>Tue Apr 06 18:05:54 +0000 2010</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>130226736</td>\n",
       "      <td>False</td>\n",
       "      <td>694206616946765824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1826</td>\n",
       "      <td>A doctor connected to Putnam Hospital Center s...</td>\n",
       "      <td>Nyack &amp; Piermont, NY</td>\n",
       "      <td>Nyack-Piermont Patch is your source for local ...</td>\n",
       "      <td>13669</td>\n",
       "      <td>NyackPatch</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>Tue Jun 22 19:44:23 +0000 2010</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>158467267</td>\n",
       "      <td>False</td>\n",
       "      <td>694206615101247488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>714</td>\n",
       "      <td>#FollowForFollow WHO meets to decide if Zika v...</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>Mention me after you tap that follow button fo...</td>\n",
       "      <td>79137</td>\n",
       "      <td>_Dirty_Water_</td>\n",
       "      <td>114</td>\n",
       "      <td>10</td>\n",
       "      <td>114</td>\n",
       "      <td>Thu Jul 19 21:04:22 +0000 2012</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>705784747</td>\n",
       "      <td>False</td>\n",
       "      <td>694206612680998913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2033</td>\n",
       "      <td>A doctor connected to Putnam Hospital Center s...</td>\n",
       "      <td></td>\n",
       "      <td>Local news and conversation from Hudson Valley...</td>\n",
       "      <td>6231</td>\n",
       "      <td>HVPatch</td>\n",
       "      <td>871</td>\n",
       "      <td>41</td>\n",
       "      <td>871</td>\n",
       "      <td>Tue Jul 10 18:33:10 +0000 2012</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>632210824</td>\n",
       "      <td>False</td>\n",
       "      <td>694206612601491461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2553</td>\n",
       "      <td>RT @CNN: The #Zika virus could complicate the ...</td>\n",
       "      <td>En pèlerinage sur terre.</td>\n",
       "      <td>Je revendique le droit de donner mon avis sur ...</td>\n",
       "      <td>63435</td>\n",
       "      <td>PierreChrist_</td>\n",
       "      <td>691</td>\n",
       "      <td>9419</td>\n",
       "      <td>691</td>\n",
       "      <td>Fri Mar 06 13:15:41 +0000 2009</td>\n",
       "      <td>41</td>\n",
       "      <td>66</td>\n",
       "      <td>23061341</td>\n",
       "      <td>False</td>\n",
       "      <td>694206609422172161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   followers_count                                               text  \\\n",
       "0             1596  A doctor connected to Putnam Hospital Center s...   \n",
       "1             1826  A doctor connected to Putnam Hospital Center s...   \n",
       "2              714  #FollowForFollow WHO meets to decide if Zika v...   \n",
       "3             2033  A doctor connected to Putnam Hospital Center s...   \n",
       "4             2553  RT @CNN: The #Zika virus could complicate the ...   \n",
       "\n",
       "                   location  \\\n",
       "0              New City, NY   \n",
       "1      Nyack & Piermont, NY   \n",
       "2                     Kenya   \n",
       "3                             \n",
       "4  En pèlerinage sur terre.   \n",
       "\n",
       "                                         description  statuses_count  \\\n",
       "0      New City Patch is your source for local news.           12248   \n",
       "1  Nyack-Piermont Patch is your source for local ...           13669   \n",
       "2  Mention me after you tap that follow button fo...           79137   \n",
       "3  Local news and conversation from Hudson Valley...            6231   \n",
       "4  Je revendique le droit de donner mon avis sur ...           63435   \n",
       "\n",
       "     screen_name  following  favourites_count  friends_count  \\\n",
       "0   NewCityPatch         51                 7             51   \n",
       "1     NyackPatch         55                 0             55   \n",
       "2  _Dirty_Water_        114                10            114   \n",
       "3        HVPatch        871                41            871   \n",
       "4  PierreChrist_        691              9419            691   \n",
       "\n",
       "                       created_at  retweet_count  listed_count    user_id  \\\n",
       "0  Tue Apr 06 18:05:54 +0000 2010              0            54  130226736   \n",
       "1  Tue Jun 22 19:44:23 +0000 2010              0            41  158467267   \n",
       "2  Thu Jul 19 21:04:22 +0000 2012              0            35  705784747   \n",
       "3  Tue Jul 10 18:33:10 +0000 2012              0            46  632210824   \n",
       "4  Fri Mar 06 13:15:41 +0000 2009             41            66   23061341   \n",
       "\n",
       "  verified            tweet_id  \n",
       "0    False  694206616946765824  \n",
       "1    False  694206615101247488  \n",
       "2    False  694206612680998913  \n",
       "3    False  694206612601491461  \n",
       "4    False  694206609422172161  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df = pd.DataFrame(data = tweets_dict, columns = tweets_dict.keys())\n",
    "tweets_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 15)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#exporting to csv\n",
    "tweets_df.to_csv('zika_tweets_per_tweet_2.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 16)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zika = pd.read_csv('zika_tweets_per_tweet_2.csv')\n",
    "zika.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#selecting subset of variables identified in HW1\n",
    "taska = zika[['user_id','listed_count','retweet_count','followers_count','following']]\n",
    "taska.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "retweet_by_user = pd.DataFrame(taska.groupby('user_id')['retweet_count'].sum())\n",
    "user_info = taska.groupby('user_id')[['listed_count','followers_count','following']].mean()\n",
    "taska_by_user = pd.merge(user_info,retweet_by_user,left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Log-transform all features\n",
    "def log_trans(x):\n",
    "    return np.log(x+1)  # +1 to take care of 0 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for column in taska_by_user:\n",
    "    taska_by_user[column] = log_trans(taska_by_user[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Coefficients learnt from HW1:\n",
    "follower = 0.10919318\n",
    "following = -0.00270281\n",
    "listed = 0.2451884\n",
    "retweet = 0.04542407"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rescale s.t. sum up to 1\n",
    "scaler = 1/(follower+following+listed+retweet)\n",
    "follower *= scaler\n",
    "following *= scaler\n",
    "listed *= scaler\n",
    "retweet *= scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listed_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>following</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>influence_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>171496247</th>\n",
       "      <td>7.337588</td>\n",
       "      <td>11.763783</td>\n",
       "      <td>8.685247</td>\n",
       "      <td>8.925986</td>\n",
       "      <td>0.000162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8005492</th>\n",
       "      <td>8.396606</td>\n",
       "      <td>12.067936</td>\n",
       "      <td>5.993961</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727472528</th>\n",
       "      <td>7.539559</td>\n",
       "      <td>10.876159</td>\n",
       "      <td>8.123558</td>\n",
       "      <td>5.568345</td>\n",
       "      <td>0.000267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241258612</th>\n",
       "      <td>7.224025</td>\n",
       "      <td>10.747702</td>\n",
       "      <td>9.105646</td>\n",
       "      <td>3.891820</td>\n",
       "      <td>0.000410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1358290958</th>\n",
       "      <td>6.230481</td>\n",
       "      <td>10.277978</td>\n",
       "      <td>10.090465</td>\n",
       "      <td>8.871505</td>\n",
       "      <td>0.000491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35315865</th>\n",
       "      <td>6.633318</td>\n",
       "      <td>9.319284</td>\n",
       "      <td>7.825645</td>\n",
       "      <td>7.841100</td>\n",
       "      <td>0.000552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597996609</th>\n",
       "      <td>6.593045</td>\n",
       "      <td>10.445492</td>\n",
       "      <td>9.941457</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29702055</th>\n",
       "      <td>5.690359</td>\n",
       "      <td>8.617762</td>\n",
       "      <td>6.061457</td>\n",
       "      <td>7.555382</td>\n",
       "      <td>0.001222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154532994</th>\n",
       "      <td>6.546785</td>\n",
       "      <td>9.784084</td>\n",
       "      <td>6.084499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21330040</th>\n",
       "      <td>6.838405</td>\n",
       "      <td>8.733308</td>\n",
       "      <td>4.624973</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            listed_count  followers_count  following  retweet_count  \\\n",
       "user_id                                                               \n",
       "171496247       7.337588        11.763783   8.685247       8.925986   \n",
       "8005492         8.396606        12.067936   5.993961       0.000000   \n",
       "727472528       7.539559        10.876159   8.123558       5.568345   \n",
       "1241258612      7.224025        10.747702   9.105646       3.891820   \n",
       "1358290958      6.230481        10.277978  10.090465       8.871505   \n",
       "35315865        6.633318         9.319284   7.825645       7.841100   \n",
       "597996609       6.593045        10.445492   9.941457       0.693147   \n",
       "29702055        5.690359         8.617762   6.061457       7.555382   \n",
       "154532994       6.546785         9.784084   6.084499       0.000000   \n",
       "21330040        6.838405         8.733308   4.624973       0.000000   \n",
       "\n",
       "            influence_score  \n",
       "user_id                      \n",
       "171496247          0.000162  \n",
       "8005492            0.000211  \n",
       "727472528          0.000267  \n",
       "1241258612         0.000410  \n",
       "1358290958         0.000491  \n",
       "35315865           0.000552  \n",
       "597996609          0.000953  \n",
       "29702055           0.001222  \n",
       "154532994          0.001240  \n",
       "21330040           0.001369  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating likelihood of being influence (0 is more likely to be influencer, 1 is less likely)\n",
    "taska_by_user['influence_score'] = 1 / (1 + np.exp(taska_by_user['listed_count'] * listed + taska_by_user['followers_count'] * follower + \n",
    "                                                taska_by_user['following'] * following + taska_by_user['retweet_count'] * retweet ) )\n",
    "\n",
    "\"\"\"\n",
    "# calculating influencer score using logistic coefficients as linear coefficients\n",
    "taska_by_user['influence_score'] = 1 / (1 + np.exp(taska_by_user['listed_count'] * listed + taska_by_user['followers_count'] * follower + \n",
    "                                                taska_by_user['following'] * following + taska_by_user['retweet_count'] * retweet ) )\n",
    "\"\"\"\n",
    "\n",
    "# Rank by influence_score and get TOP 50\n",
    "Influencer_top50 = taska_by_user.sort_values(by = 'influence_score', ascending = True)[:50]\n",
    "# need to ascending=False if using logistic coefficients as linear coefficients\n",
    "Influencer_top50.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions:\n",
    "1. The coefficients are learnt on log(diff), can we directly apply that in the absolute case?\n",
    "2. Why do we have to normalize features, given that coefficients are learnt from non-normalized features? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import fnmatch\n",
    "import nltk.data\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zika = pd.read_csv(\"zika_tweets_per_tweet_2.csv\", encoding='utf8')\n",
    "def WordProcess(series):\n",
    "    \"\"\"This function will tokenize each row in a given series and return a list\"\"\"\n",
    "    tokenized = []\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    for i in range(len(series)):\n",
    "        tokenized.append(tokenizer.tokenize(series[i]))\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#random sample 5000 tweets from the 9717 tweets we scraped\n",
    "zika_5000 = zika.sample(n=5000, random_state = 123)\n",
    "zika_df = zika_5000.reset_index(drop=True)\n",
    "tweet = zika_df['text']\n",
    "word_list = WordProcess(tweet) #tokenized each tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create an empty dataframe with 3 columns and 5000 rows\n",
    "columns = ['Column1', 'Column2', 'Column3']\n",
    "df = pd.DataFrame(index = range(len(word_list)), columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fill in the dataframe with retweets\n",
    "for index, tweet in enumerate(word_list):\n",
    "    for ind, word in enumerate(tweet):\n",
    "        if word =='RT': #if RT is in the tweet, the original tweet is word behind RT\n",
    "            df.ix[index]['Column2'] = '@'+tweet[ind+1]\n",
    "            df.ix[index]['Column3'] = word\n",
    "            df.ix[index]['Column1'] = '@'+zika_df['screen_name'][index]\n",
    "df = df.fillna('none')\n",
    "for i in range(len(df)):\n",
    "    #if there are no RT, then it's an original tweet\n",
    "    if df['Column1'][i] == 'none':\n",
    "        df.ix[i]['Column1'] = '@'+zika_df['screen_name'][i]\n",
    "        df.ix[i]['Column2'] = '@'+zika_df['screen_name'][i]\n",
    "        df.ix[i]['Column3'] = 'Tweet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('task_B.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
