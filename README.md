# MSBA_SMA_HW2

## Task
0. Write a python script to crawl 5000 tweets w/ twitter API
1. Calculate an influencial score for each user, get top 50 influencers
2. Create a user network using retweets, mentions, and replies


## Plan
#### Jan 25-26
1. Get tweeter authorization (Check)
2. Write a crawler (Crawling part figured out; Formatting to csv remains to be solved) (Check on Jan 29)

#### Jan 27
0. Format Tweets to nice, analyzable csv format (Check on Jan 29)
1. Communicate w/ team on topic choosing (Check : Zika)
2. Finish up task 1 (Check on Jan 30)
3. Recap NLTK, head start on task 2 (Vivian got it on Jan 29)


#### Jan 29
1. Finish up task 1 (Check on Jan 30)
 -- 2 Questions:
    (1) Can we apply coefficients learnt from a different data set w/ different data, structure, even form of features?
    (2) If "yes" to (1), why do we need to normalize features?

#### Jan 30-31
1. Task 2 (Vivian got it on Jan 29)
2. Play around w/ gephi
